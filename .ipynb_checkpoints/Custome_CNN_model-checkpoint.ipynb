{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import Add, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras.layers import ReLU, MaxPool2D, GlobalAvgPool2D, LeakyReLU, AveragePooling2D\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from plotly.subplots import make_subplots\n",
    "from tensorflow.keras.layers.experimental import preprocessing as ps\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import glob\n",
    "print('tf version', tf.__version__)\n",
    "print('keras version', tf.keras.__version__)\n",
    "print('gpu is ','available' if tf.config.list_physical_devices('GPU') else 'not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756d1e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_train_128.pkl', 'rb')\n",
    "X_train = pickle.load(file)\n",
    "\n",
    "file = open('y_train_128.pkl', 'rb')\n",
    "y_train = pickle.load(file)\n",
    "\n",
    "file = open('X_test_128.pkl', 'rb')\n",
    "X_test = pickle.load(file)\n",
    "\n",
    "file = open('y_test_128.pkl', 'rb')\n",
    "y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86273ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b550d-0e73-4629-9410-d488baba9735",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functional Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393edc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, filters, kernel_size, strides=1):\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size, \n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bslr(x):\n",
    "    x = conv_layer(x, filters=32, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = conv_layer(x, filters=49, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=128, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=256, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=512, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=728, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=1024, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = conv_layer(x, filters=1024, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = conv_layer(x, filters=1024, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=728, kernel_size=3, strides=2)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv_layer(x, filters=512, kernel_size=3, strides=2)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation=LeakyReLU())(x)\n",
    "    x = Dense(128, activation=LeakyReLU())(x)\n",
    "    x = Dense(64, activation=LeakyReLU())(x)\n",
    "    x = Dense(49, activation='softmax')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=[128, 128, 3])\n",
    "\n",
    "x = bslr(input)\n",
    "\n",
    "base_model = Model(input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267935f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sequential Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff803e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Our Architecture 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1 92%\n",
    "model = Sequential()\n",
    "model.add(Conv2D(49,(3,3),activation='relu', input_shape=(128,128,3)))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(512,(3,3),activation='relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(768,(3,3),activation='relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(768, activation=LeakyReLU()))\n",
    "model.add(Dense(512, activation=LeakyReLU()))\n",
    "model.add(Dense(256, activation=LeakyReLU()))\n",
    "model.add(Dense(128, activation=LeakyReLU()))\n",
    "model.add(Dense(49, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f7362",
   "metadata": {},
   "source": [
    "### Recognition Bangla Sign Language using Convolutional Neural Network 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd96ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(32,(5,5),activation='relu', input_shape=(128,128,3)))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_2.add(Conv2D(64,(5,5),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_2.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_2.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_2.add(Conv2D(384,(3,3),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(Conv2D(512,(3,3),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(GlobalAvgPool2D())\n",
    "model_2.add(Dense(84, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(49, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1b8a0",
   "metadata": {},
   "source": [
    "### Image-based Bengali Sign Language Alphabet Recognition for Deaf and Dumb Community 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(64,(3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model_3.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_3.add(Conv2D(128,(3,3), activation='relu'))\n",
    "model_3.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_3.add(Conv2D(256,(3,3), activation='relu'))\n",
    "model_3.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_3.add(Conv2D(512,(3,3), activation='relu'))\n",
    "model_3.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_3.add(Conv2D(512,(3,3), activation='relu'))\n",
    "\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(GlobalAvgPool2D())\n",
    "model_3.add(Dense(256, activation='relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(49, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613f5fa",
   "metadata": {},
   "source": [
    "### Hand Sign to Bangla Speech: A Deep Learning in Vision based system for Recognizing Hand Sign Digits and Generating Bangla Speech 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea600f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model_4.add(MaxPool2D((2,2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_4.add(MaxPool2D((2,2)))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(96, activation='relu'))\n",
    "model_4.add(Dense(64, activation='relu'))\n",
    "model_4.add(Dense(49, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7c0bc",
   "metadata": {},
   "source": [
    "### Bangla Sign Language Detection using SIFT and CNN 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (7,7), activation='relu', input_shape=(128,128,3)))\n",
    "model_5.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_5.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model_5.add(MaxPool2D((2,2)))\n",
    "model_5.add(Dropout(0.5))\n",
    "\n",
    "model_5.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_5.add(MaxPool2D((2,2)))\n",
    "\n",
    "model_5.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model_5.add(MaxPool2D((2,2)))\n",
    "model_5.add(Dropout(0.5))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(128, activation='relu'))\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(49, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b41c3",
   "metadata": {},
   "source": [
    "### Ishara-Lipi: The First Complete MultipurposeOpen Access Dataset of Isolated Characters forBangla Sign Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f96c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Conv2D(32, (5,5), activation='relu', input_shape=(128,128,3)))\n",
    "model_6.add(Conv2D(32, (5,5), activation='relu'))\n",
    "model_6.add(MaxPool2D((5,5)))\n",
    "model_6.add(Dropout(0.25))\n",
    "\n",
    "model_6.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_6.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_6.add(MaxPool2D((2,2)))\n",
    "model_6.add(Dropout(0.25))\n",
    "\n",
    "model_6.add(Flatten())\n",
    "model_6.add(Dense(256, activation='relu'))\n",
    "model_6.add(Dropout(0.5))\n",
    "model_6.add(Dense(49, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model_6.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45985a-5b9a-43b4-b932-ec19e64e4975",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2433d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_class = 49\n",
    "epoch = 100\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(base_model)\n",
    "\n",
    "model_5.compile(loss ='categorical_crossentropy', optimizer ='rmsprop', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model_6.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model_6.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=58,\n",
    "    epochs=epoch,\n",
    "    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8a624-62de-42c5-af7f-b7d0e4edd82b",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6325be-7d78-4ac9-98e9-d3310cbae9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(H.history[\"accuracy\"])\n",
    "plt.plot(H.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b239d8-084e-4e2b-98ba-1c77e9ba865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(H.history['loss'])\n",
    "plt.plot(H.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model_6.predict(X_test,batch_size=1), axis=1) \n",
    "\n",
    "print('Classification Report')\n",
    "y_classes = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "report = classification_report(y_classes, y_pred)\n",
    "print(report)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "cm = confusion_matrix(y_classes, y_pred)\n",
    "_=sns.heatmap(cm.T, annot=True, fmt='d', cbar=True, square=True)\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Predicted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
