{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e858e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version 2.8.0\n",
      "keras version 2.8.0\n",
      "gpu is  available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import Add, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import ReLU, MaxPool2D, GlobalAvgPool2D, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from plotly.subplots import make_subplots\n",
    "from tensorflow.keras.layers.experimental import preprocessing as ps\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import glob\n",
    "print('tf version', tf.__version__)\n",
    "print('keras version', tf.keras.__version__)\n",
    "print('gpu is ','available' if tf.config.list_physical_devices('GPU') else 'not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0c84fc",
   "metadata": {},
   "source": [
    "## Convulation layer with BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29bf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, filters, kernel_size, strides=1):\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size, \n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05a46c",
   "metadata": {},
   "source": [
    "## Separable Convulation layer with BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22275a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_conv_layer(x, filters, kernel_size, strides=1):\n",
    "    x = SeparableConv2D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=strides,\n",
    "                        padding='same',\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7a8d9",
   "metadata": {},
   "source": [
    "## Xception model Entry Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb3802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_flow(x):\n",
    "    x = conv_layer(x, filters=32, kernel_size=3, strides=2)\n",
    "    x = ReLU()(x)\n",
    "    x = conv_layer(x, filters=64, kernel_size=3)\n",
    "    tensor = ReLU()(x)\n",
    "    \n",
    "    x = sep_conv_layer(tensor, filters=128, kernel_size=3)\n",
    "    x = ReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=256, kernel_size=3)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    tensor = conv_layer(tensor, filters=256, kernel_size=1, strides=2)\n",
    "    \n",
    "    x = Add()([tensor, x])\n",
    "    x = ReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=256, kernel_size=3)\n",
    "    x = ReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=256, kernel_size=3)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    tensor = conv_layer(tensor, filters=256, kernel_size=1, strides=2)\n",
    "    \n",
    "    x = Add()([tensor, x])\n",
    "    x = ReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=512, kernel_size=3)\n",
    "    x = ReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=1024, kernel_size=3)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    tensor = conv_layer(tensor, filters=1024, kernel_size=1, strides=2)\n",
    "    x = Add()([tensor, x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71b00c",
   "metadata": {},
   "source": [
    "## Xception model Middle flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17697781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_flow(tensor):\n",
    "    for _ in range(4):\n",
    "        x = ReLU()(tensor)\n",
    "        x = sep_conv_layer(x, filters=1024, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_layer(x, filters=1024, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_layer(x, filters=1024, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        \n",
    "        tensor = Add()([tensor, x])\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1276551",
   "metadata": {},
   "source": [
    "## Xception model Exit flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e694a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_flow(tensor):\n",
    "    x = LeakyReLU()(tensor)\n",
    "    x = sep_conv_layer(x, filters=728, kernel_size=3)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=512, kernel_size=3)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    tensor = conv_layer(tensor, filters=512, kernel_size=1, strides=2)\n",
    "    \n",
    "    x = Add()([tensor, x])\n",
    "    x = sep_conv_layer(x, filters=512, kernel_size=3)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = sep_conv_layer(x, filters=256, kernel_size=3)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    x = Dense(128, activation=LeakyReLU())(x)\n",
    "    x = Dense(64, activation=tf.keras.layers.LeakyReLU())(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(units=49, activation='softmax')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3513ab7",
   "metadata": {},
   "source": [
    "## Model creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa591f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=[128, 128, 3])\n",
    "\n",
    "x = entry_flow(input)\n",
    "x = middle_flow(x)\n",
    "output = exit_flow(x)\n",
    "\n",
    "base_model = Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307d1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_class = 49\n",
    "epoch = 75\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "model.compile(loss ='categorical_crossentropy', optimizer ='adam', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b627d45-3961-425e-9761-5751a7165663",
   "metadata": {},
   "source": [
    "## BDSL Dataset Training 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad881c-5433-4042-86e6-fe0aa67bb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_train_128.pkl', 'rb')\n",
    "X_train = pickle.load(file)\n",
    "\n",
    "file = open('y_train_128.pkl', 'rb')\n",
    "y_train = pickle.load(file)\n",
    "\n",
    "file = open('X_test_128.pkl', 'rb')\n",
    "X_test = pickle.load(file)\n",
    "\n",
    "file = open('y_test_128.pkl', 'rb')\n",
    "y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3468d25b-604a-469f-b47e-be544fb474e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11774, 128, 128, 3)\n",
      "(11774, 49)\n",
      "(2940, 128, 128, 3)\n",
      "(2940, 49)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9379dedc-7484-448c-93e9-e62c19694759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 49)                16078025  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,078,025\n",
      "Trainable params: 16,040,281\n",
      "Non-trainable params: 37,744\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3416ce-9208-43ca-be04-8b88462abdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "203/203 [==============================] - 74s 329ms/step - loss: 3.2722 - accuracy: 0.1431 - val_loss: 3.9035 - val_accuracy: 0.0204\n",
      "Epoch 2/75\n",
      "203/203 [==============================] - 66s 326ms/step - loss: 1.4847 - accuracy: 0.5476 - val_loss: 3.5019 - val_accuracy: 0.0959\n",
      "Epoch 3/75\n",
      "203/203 [==============================] - 66s 326ms/step - loss: 0.7187 - accuracy: 0.7692 - val_loss: 0.8735 - val_accuracy: 0.7122\n",
      "Epoch 4/75\n",
      "203/203 [==============================] - 67s 331ms/step - loss: 0.4475 - accuracy: 0.8543 - val_loss: 0.9158 - val_accuracy: 0.7313\n",
      "Epoch 5/75\n",
      "203/203 [==============================] - 67s 331ms/step - loss: 0.3027 - accuracy: 0.8999 - val_loss: 0.7248 - val_accuracy: 0.7867\n",
      "Epoch 6/75\n",
      "203/203 [==============================] - 68s 333ms/step - loss: 0.2225 - accuracy: 0.9243 - val_loss: 0.8183 - val_accuracy: 0.7816\n",
      "Epoch 7/75\n",
      "203/203 [==============================] - 68s 333ms/step - loss: 0.1903 - accuracy: 0.9387 - val_loss: 1.6583 - val_accuracy: 0.6616\n",
      "Epoch 8/75\n",
      "203/203 [==============================] - 68s 334ms/step - loss: 0.1496 - accuracy: 0.9517 - val_loss: 1.5628 - val_accuracy: 0.6422\n",
      "Epoch 9/75\n",
      "203/203 [==============================] - 68s 333ms/step - loss: 0.1141 - accuracy: 0.9615 - val_loss: 0.7357 - val_accuracy: 0.8153\n",
      "Epoch 10/75\n",
      "203/203 [==============================] - 68s 334ms/step - loss: 0.1590 - accuracy: 0.9488 - val_loss: 1.0274 - val_accuracy: 0.7585\n",
      "Epoch 11/75\n",
      "203/203 [==============================] - 68s 334ms/step - loss: 0.1009 - accuracy: 0.9666 - val_loss: 0.8591 - val_accuracy: 0.7728\n",
      "Epoch 12/75\n",
      "203/203 [==============================] - 69s 340ms/step - loss: 0.0871 - accuracy: 0.9726 - val_loss: 1.3044 - val_accuracy: 0.7303\n",
      "Epoch 13/75\n",
      "203/203 [==============================] - 68s 335ms/step - loss: 0.0645 - accuracy: 0.9804 - val_loss: 0.6845 - val_accuracy: 0.8241\n",
      "Epoch 14/75\n",
      "203/203 [==============================] - 68s 337ms/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.7591 - val_accuracy: 0.8231\n",
      "Epoch 15/75\n",
      "203/203 [==============================] - 69s 339ms/step - loss: 0.0995 - accuracy: 0.9701 - val_loss: 0.9609 - val_accuracy: 0.8003\n",
      "Epoch 16/75\n",
      "203/203 [==============================] - 69s 338ms/step - loss: 0.0625 - accuracy: 0.9809 - val_loss: 0.6621 - val_accuracy: 0.8534\n",
      "Epoch 17/75\n",
      "203/203 [==============================] - 69s 340ms/step - loss: 0.0591 - accuracy: 0.9818 - val_loss: 0.3845 - val_accuracy: 0.9112\n",
      "Epoch 18/75\n",
      "203/203 [==============================] - 68s 334ms/step - loss: 0.0732 - accuracy: 0.9768 - val_loss: 1.1255 - val_accuracy: 0.7422\n",
      "Epoch 19/75\n",
      "203/203 [==============================] - 68s 335ms/step - loss: 0.0627 - accuracy: 0.9827 - val_loss: 0.5026 - val_accuracy: 0.8881\n",
      "Epoch 20/75\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9858"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=58,\n",
    "    epochs=epoch,\n",
    "    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baec240-7704-461b-ba3f-5af8c342392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(H.history[\"accuracy\"])\n",
    "plt.plot(H.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d7523-4240-4c19-b741-8ac15cac20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(H.history['loss'])\n",
    "plt.plot(H.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762b873-702a-49e4-a25e-e8fe361a5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test,batch_size=1), axis=1) \n",
    "\n",
    "print('Classification Report')\n",
    "y_classes = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "report = classification_report(y_classes, y_pred)\n",
    "print(report)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "cm = confusion_matrix(y_classes, y_pred)\n",
    "_=sns.heatmap(cm.T, annot=True, fmt='d', cbar=True, square=True)\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Predicted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
